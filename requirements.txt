numpy==1.24.0
pandas==1.5.3
matplotlib==3.6.3
seaborn==0.11.2
Pillow==9.5.0  # Pillow is the modern fork of PIL
scikit-learn==1.1.3
tensorflow==2.12.0  # Assuming TensorFlow 2.12.0 for compatibility
keras==2.6.0
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from collections import Counter
import numpy as np

for result in results:
    question = result['question']
    phrases = result['phrases']
    cluster_labels = result['cluster_labels']

    # Create a TF-IDF matrix for the phrases
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(phrases)

    # Perform PCA to reduce the dimensionality of the data
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X.toarray())

    # Count the frequency of each phrase in each cluster
    cluster_counts = []
    for i in set(cluster_labels):
        cluster_phrases = [phrase for j, phrase in enumerate(phrases) if cluster_labels[j] == i]
        cluster_counts.append(dict(Counter(cluster_phrases)))

    # Create a figure with subplots for each cluster
    num_clusters = len(set(cluster_labels))
    fig, axes = plt.subplots(1, num_clusters, figsize=(16, 6))
    if num_clusters == 1:
        axes = [axes]

    # Plot the keyword clusters for each cluster
    for i, ax in enumerate(axes):
        top_phrases = list(cluster_counts[i].keys())[:50]
        top_phrase_indices = [j for j, label in enumerate(cluster_labels) if phrases[j] in top_phrases and label == i]
        top_phrase_points = X_pca[top_phrase_indices]
        ax.scatter(top_phrase_points[:, 0], top_phrase_points[:, 1], label=f'Cluster {i}')
        for j, phrase in enumerate(top_phrases):
            ax.annotate(phrase, (top_phrase_points[j, 0], top_phrase_points[j, 1]), fontsize=8)
        ax.set_title(f'Cluster {i}')
        ax.set_xlabel('PC1')
        ax.set_ylabel('PC2')
        ax.legend()

    fig.suptitle(f'Keyword Clusters for Question: {question}', fontsize=16)
    plt.tight_layout()
    plt.show()
